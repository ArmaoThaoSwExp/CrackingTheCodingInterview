Cracking the coding interview 


- Remember to look at the problem of traversing through a grid and seeing which is the longest path.  Return the integers.

- Make sure to know, use, implement, and complexity for data structures, algorithms, and concepts.

Data Structures:
    (done)Linked List
    
    (done)Binary Trees
    
    (done)Tries
    
    (done)Stacks
    
    (done)Queues
    
    (done)Vectors/ArrayLists
    
    (done)Hash Tables
    
    NP-complete problems: traveling salesman and knapsack problem.
    
    Dijkstra's algorithm
    
    A*
    
    Graphs: objects and pointers, matrix, and adjacency list
        http://web.cecs.pdx.edu/~sheard/course/Cs163/Doc/Graphs.html
        
        Contains vertices and edges
        Vertex - each location/stop
        Edge - connects two vertices
    
        undirected graphs
            - edges do not have a direction.
            
        directed graphs
            - edges have a direction associated with them.
        
        
        path: a sequence of vertices such that there is an edge from each vertex to the next in sequence.
            If the start and end vertices are the same, path is called cycle.
            Path is called simple if it includes every vertex only once.
    
        weighted graph
            Every edge is associated with a real number called edge weight.
    
    
        adjacency matrix
        
                    1,  2, 3, 4, 5
             1   [ 0   0  0  1  0]
             2   [ 0   0  0  1  1]
             3   [ 0   0  0  0  1]
             4   [ 1   1  0  0  1]
             5   [ 0   1  1  1  0]
    
            1 has 4 as a vertex
                (1, 4), (4, 1) are both set to 1
            4 has 2 and 5 as vertices
                (2, 4), (4, 2), (4, 5), and (5, 4) are set to 1
            3 has 5 as a vertex
                (3, 5). (5, 3) are set to 1
            2 has 4 and 5 as vertices
                (2, 4), (4, 2), (2, 5), and (5, 2) are set to 1
            5 has 3, 2, and 4 as vertices
                (5, 3), (3, 5), (5, 2), (2, 5), (5, 4), (4, 5) are set to 1
                
             Pros:
                - Add/remove/check can be done in O(1) time
                - very easy to program
                
             Cons:
                - Consumes huge amounts of memory to store big graphs.
                - 2 graph categories:
                    - sparse
                        - not much edges
                        - number of edges is much less than the square of the number of vertices
                    - dense 
                        - number of edges is equivalent to the square of the number of vertices
                        - idea for dense graphs
                - since you have to scan over an entire row to see all the edges of a vertex, it means O(V) complexity.
                    - So DFS results in overall complexity of O(V^2)
                    - Using adjacent list instead of adjacent matrix would result in complexity of O(V + E)
                - Requires huge efforts for adding/removing.  So for large and dynamic graphs, it makes it quite slow.
         
         adjacent list
            Uses a list to store adjacent vertices to the current vertex.  Good for sparse graphs.
            
            Pros:
                - Store graphs in more compact form.
                - Allows retrieval of adjacent vertices in O(1) time, which is a big advantage for some algorithms.
                
            Cons:
                - Adding/removing an edge is O(E / V) on average.
                - Checking for an edge between two vertices can be done in O(E / V) when adjacent vertices are unordered or O(log2(E / V)) when it is sorted.
                - Dynamically changing of vertices number doesn't allow us to make an efficient implementation.  Adding a new vertex is O(V) but removal results in O(E).
            
            
    
    Threading monitor
    
    Understand routers, domain name servers, load balancers, firewalls,
    
    
    (done)AVL Tree or Adelson, Velski, and Landis Tree (Come back and do implementation if I have time):
        - height balancing binary search trees
        - checks left and right sub-trees and assures that the difference is not more than 1.
        - The difference is called the balance factor.
        - To balance itself, an AVL tree uses 4 kinds of rotation:
            - left rotation (single rotation)
                We have root nohromeand right child node B.
                A new child node, C, is inserted as the right child node of B, which makes the tree unbalanced.
                To solve this, we do a left rotation by making B the new root node,
20.2320.
41048                  A becomes the left child node of B
    4                C stays the right child node of B.
            - right rotation (single rotation)
                We have root node C with a left child node called B.
                A new child node, A, is inserted as the left child node of B, which makes the tree unbalanced.
                To solve this, we do a right rotation by making B the new root node,
                    A stays the left child node of B.
                    C becomes he right child node of B.
            - left-right rotation (double rotations)
                Need picture!!!
                Essentially, do a left rotation and then a right rotation.
            - right-left rotation (double rotations)
                Need image!!!
                Essentially, do a right rotation and then a left rotation.
    
    Spanning Tree (Come back and do implementation and read details if I have time)
    
Algorithms:
    (done)Breadth First Search
    
    (done)Depth First Search
    
    (done)Binary Search
    
    
    (done)Merge Sort
    
    
    (done)Quick Sort
    
    
    Strassen's Matrix Multiplication (come back if I have time)

    shell sort (come back if I have time)
    
    
    Greedy Approach
        The algorithm is designed to achieve optimum solution for the given problem.
        The closest solution that seems to provide optimum solution is chosen.
        Generally, greedy algorithms do not provide globally optimized solutions.
        
        Example: counting coins
            coin values provided: $1, $2, $5, $10
            
            1) count to $18
                Greedy: $10 (1), $5(1), $2(1), and $1(1)
                
            If we slightly change the problem,
            count to $15 with coins of $1, $7, and $10,
            Greedy: $10 (1), $1 (6) = $15
            Not very efficient
            Whereas a non-Greedy solution: $7 (2), $1(1) x= $15

    Divide & Conquer
        Problem at hand is divided into smaller sub-problems, and then each sub-problem is solved independently.
        The smallest possible sub-problems are solved, and then merged back together to obtain the solution of the original problem.

    Dynamic Programming
        Problem is divided into similar sub-problems, so that the results can be reused among the sub-problems.
        Uses memorization: optimization technique in which results of expensive function calls and returning the cached results when the same inputs occur again.

Concepts:
    (done)Bit Manipulation
    
    
    (done)Singleton Design Pattern
    
    
    (done)Factory Design Pattern
    
    
    (Done)Memory (Stack vs Heap)

    
    (Done)Recursion
    
    
    (done)Big-O Time

    
    
Exercises to Implement:

3.5) Implement a MyQueue class which implements a queue using two stacks.

3.6) Write a program to sort a stack in ascending order.  You should not make any assumptions about how the stack is implemented.  The following are the only functions that should be used to write this program: push, pop, peek, and isEmpty.


Not in book) Implement adjacent matrix graph.

Not in book) Review binary search tree's algorithm for balancing the tree and also refactoring when needed.


4.4) Given a binary search tree, design an algorithm which creates a linked list of all the nodes at each depth (e.g. if you have a tree with depth D, you'll have D linked lists).

4.6) Common ancestor (lowest common ancestor) in a non-bst 

    - http://www.geeksforgeeks.org/lowest-common-ancestor-binary-tree-set-1/
    
    - We know that a node is the lowest common ancestor if one node is a left child and the other node is the right child.
        - if p and q are on the left side, traverse left subtree.
        - if p and q are on the right side, traverse right subtree.
        - otherwise, the current node is the lower common ancestor.

    - For BST, which is on average O(height of tree)
        - Simple traverse from the root.
            - the first node we find that is between n1 and n2 is the LCA.
            - if node < n1 and node < n2, then n1 and n2 are to the right of the node.
            - if node > n1 and node < n2, then n1 and n2 are to the left of the node.
            

5.3) Given an integer, print the next smallest and next largest number that have the same number of 1 bits in their binary represenation.


8.3) Write a method that returns all subsets of a set.


8.7) Given an infinite number of quarters (25 cents), dimes (10 cents), nickels(5 cents), and pennies (1 cent), write code to calculate the number of ways of representing n cents.



8.8) Write an algorithm to print all ways of arranging eight queens on a chess board so that none of them shre the same row, column or diagonal.


9.4) Need to look at external sort.

9.6) Given a matrix in which each row and each column is sorted, write a method to find an element in it.


- B+ Tree

- Selection rank


20.4)


